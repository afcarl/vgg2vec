{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'image'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadcaffe_wrap = require 'loadcaffe_wrapper'\n",
    "json = require 'json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmd = torch.CmdLine()\n",
    "\n",
    "-- Basic options\n",
    "cmd:option('-style_dir', 'in/', 'Style input directory')\n",
    "cmd:option('-tmp_dir', 'tmp/', 'Directory to store vectors on disk')\n",
    "cmd:option('-gpu', -1, 'Zero-indexed ID of the GPU to use; for CPU mode set -gpu = -1')\n",
    "\n",
    "-- Other options\n",
    "cmd:option('-pooling', 'max', 'max|avg')\n",
    "cmd:option('-proto_file', 'models/VGG_ILSVRC_19_layers_deploy.prototxt')\n",
    "cmd:option('-model_file', 'models/VGG_ILSVRC_19_layers.caffemodel')\n",
    "\n",
    "cmd:option('-content_layers', 'relu4_2', 'layers for content')\n",
    "cmd:option('-style_layers', 'relu1_1,relu1_2,relu2_1,relu2_2,relu3_1,relu3_2,relu3_3,relu3_4,relu4_1,relu4_2,relu4_3,relu4_4,relu5_1,relu5_2,relu5_3,relu5_4', 'layers for style') -- tbh all but relu6 and relu7, which cause size mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Preprocess an image before passing it to a Caffe model.\n",
    "-- We need to rescale from [0, 1] to [0, 255], convert from RGB to BGR,\n",
    "-- and subtract the mean pixel. [jcjohnson]\n",
    "function preprocess(img)\n",
    "  local mean_pixel = torch.DoubleTensor({103.939, 116.779, 123.68})\n",
    "  local perm = torch.LongTensor{3, 2, 1}\n",
    "  img = img:index(1, perm):mul(256.0)\n",
    "  mean_pixel = mean_pixel:view(3, 1, 1):expandAs(img)\n",
    "  img:add(-1, mean_pixel)\n",
    "  return img\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Returns a network that computes the CxC Gram matrix from inputs\n",
    "-- of size C x H x W â€“ jcjohnson's version\n",
    "function GramMatrix()\n",
    "    local net = nn.Sequential()\n",
    "    net:add(nn.View(-1):setNumInputDims(2))\n",
    "    local concat = nn.ConcatTable()\n",
    "    concat:add(nn.Identity())\n",
    "    concat:add(nn.Identity())\n",
    "    net:add(concat)\n",
    "    net:add(nn.MM(false, true))\n",
    "    return net\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function Style2Vec(img, cnn, style_layers, params)\n",
    "    --[[ runs img through cnn, saving the output tensor at each of style_layers\n",
    "\n",
    "    relu1_1 : FloatTensor - size: 64x64\n",
    "    relu1_2 : FloatTensor - size: 64x64\n",
    "    relu2_1 : FloatTensor - size: 128x128\n",
    "    relu2_2 : FloatTensor - size: 128x128\n",
    "    relu3_1 : FloatTensor - size: 256x256\n",
    "    relu3_2 : FloatTensor - size: 256x256\n",
    "    relu3_3 : FloatTensor - size: 256x256\n",
    "    relu3_4 : FloatTensor - size: 256x256\n",
    "    relu4_1 : FloatTensor - size: 512x512\n",
    "    relu4_2 : FloatTensor - size: 512x512\n",
    "    relu4_3 : FloatTensor - size: 512x512\n",
    "    relu4_4 : FloatTensor - size: 512x512\n",
    "    relu5_1 : FloatTensor - size: 512x512\n",
    "    relu5_2 : FloatTensor - size: 512x512\n",
    "    relu5_3 : FloatTensor - size: 512x512\n",
    "    relu5_4 : FloatTensor - size: 512x512\n",
    "    \n",
    "    Returns a Lua table with the above key-value pairs.\n",
    "    \n",
    "    --]]\n",
    "    \n",
    "    local next_style_idx = 1\n",
    "    local net = nn.Sequential()\n",
    "    local style_vec = {}\n",
    "    \n",
    "    -- Build up net from cnn\n",
    "    \n",
    "    for i = 1, #cnn do\n",
    "        if next_style_idx <= #style_layers then\n",
    "            local layer = cnn:get(i)\n",
    "            local layer_name = layer.name\n",
    "            local layer_type = torch.type(layer)\n",
    "            local is_pooling = (layer_type == 'cudnn.SpatialMaxPooling' or layer_type == 'nn.SpatialMaxPooling')\n",
    "            \n",
    "            -- add layers to net from cnn, replacing max-pooling if necessary [jcjohnson]\n",
    "            if is_pooling and params.pooling == 'avg' then\n",
    "                local msg = 'Replacing max pooling at layer %d with average pooling'\n",
    "                print(string.format(msg, i))\n",
    "                assert(layer.padW == 0 and layer.padH == 0)\n",
    "                -- kWxkH regions by step size dWxdH\n",
    "                local kW, kH = layer.kW, layer.kH\n",
    "                local dW, dH = layer.dW, layer.dH\n",
    "                local avg_pool_layer = nn.SpatialAveragePooling(kW, kH, dW, dH):float()\n",
    "                if params.gpu >= 0 then avg_pool_layer:cuda() end\n",
    "                net:add(avg_pool_layer)\n",
    "            else\n",
    "                net:add(layer)\n",
    "            end\n",
    "            \n",
    "            -- now to grab style layers\n",
    "            \n",
    "            if (layer_name == style_layers[next_style_idx]) then\n",
    "                    \n",
    "                local gram = GramMatrix():float()\n",
    "                if params.gpu >= 0 then gram = gram:cuda() end\n",
    "                local target_features = net:forward(img)\n",
    "                local target_i = gram:forward(target_features)\n",
    "                \n",
    "                target_i:div(target_features:nElement())\n",
    "\n",
    "                style_vec[layer_name] = target_i\n",
    "                -- itorch.image(target_i) -- YA THIS IS THE VECTOR!!!\n",
    "                \n",
    "                maybe_save(params)\n",
    "                \n",
    "                next_style_idx = next_style_idx + 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    return style_vec\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"function maybe_save(params)...\"]:3: Could not access ./tmp/\nstack traceback:\n\t[C]: in function 'assert'\n\t[string \"function maybe_save(params)...\"]:3: in function 'maybe_save'\n\t[string \"function maybe_save(params)...\"]:15: in main chunk\n\t[C]: in function 'xpcall'\n\t./itorch/main.lua:179: in function <./itorch/main.lua:143>\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t./itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/Users/razi/.ipython/profile_default/se...\"]:1: in main chunk",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"function maybe_save(params)...\"]:3: Could not access ./tmp/\nstack traceback:\n\t[C]: in function 'assert'\n\t[string \"function maybe_save(params)...\"]:3: in function 'maybe_save'\n\t[string \"function maybe_save(params)...\"]:15: in main chunk\n\t[C]: in function 'xpcall'\n\t./itorch/main.lua:179: in function <./itorch/main.lua:143>\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/razi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t./itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/Users/razi/.ipython/profile_default/se...\"]:1: in main chunk"
     ]
    }
   ],
   "source": [
    "function maybe_save(params)\n",
    "    local tmp = params.tmp_dir\n",
    "    assert(paths.dir(tmp), 'Could not access ./' .. tmp)\n",
    "    \n",
    "    for f in paths.files(tmp) do\n",
    "        print(f)\n",
    "    end\n",
    "    \n",
    "    print(params.label)\n",
    "    \n",
    "    torch.save(params.tmp_dir .. 'params.json')\n",
    "end\n",
    "\n",
    "params.label = 'x'\n",
    "maybe_save(params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  gpu : -1\n",
       "  pooling : max\n",
       "  content_layers : relu4_2\n",
       "  style_dir : in/\n",
       "  style_layers : relu1_1,relu1_2,relu2_1,relu2_2,relu3_1,relu3_2,relu3_3,relu3_4,relu4_1,relu4_2,relu4_3,relu4_4,relu5_1,relu5_2,relu5_3,relu5_4\n",
       "  tmp_dir : tmp/\n",
       "  proto_file : models/VGG_ILSVRC_19_layers_deploy.prototxt\n",
       "  model_file : models/VGG_ILSVRC_19_layers.caffemodel\n",
       "}\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- let's get started\n",
    "\n",
    "local arg = {} -- when running from cli, this will be defined\n",
    "params = cmd:parse(arg)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Successfully loaded models/VGG_ILSVRC_19_layers.caffemodel\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv1_1: 64 3 3 3\n",
       "conv1_2: 64 64 3 3\n",
       "conv2_1: 128 64 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv2_2: 128 128 3 3\n",
       "conv3_1: 256 128 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_2: 256 256 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_3: 256 256 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_4: 256 256 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_1: 512 256 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_1: 512 512 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_4: 512 512 3 3\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc6: 1 1 25088 4096\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc7: 1 1 4096 4096\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc8: 1 1 4096 1000\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- load caffe network image\n",
    "cnn = loadcaffe_wrap.load(params.proto_file, params.model_file, params.backend):float()\n",
    "\n",
    "if params.gpu >= 0 then\n",
    "    cnn:cuda()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  haring_color.jpg : FloatTensor - size: 3x474x475\n",
       "  haring_bw.jpg : FloatTensor - size: 3x450x338\n",
       "}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- load images\n",
    "\n",
    "style_images = {}\n",
    "\n",
    "for f in paths.iterfiles(params.style_dir) do\n",
    "    local img = image.load(params.style_dir .. f)\n",
    "    img = preprocess(img):float()\n",
    "    if params.gpu >= 0 then \n",
    "        img = img:cuda()\n",
    "    end\n",
    "    \n",
    "    -- itorch.image(img)\n",
    "    style_images[f] = img\n",
    "end\n",
    "\n",
    "print(style_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grabbing style from haring_color.jpg..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 64\n",
       " 64\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 224676\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 64\n",
       " 64\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 224676\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 128\n",
       " 128\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 56169\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 128\n",
       " 128\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 56169\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 14161\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 14161\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 14161\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 14161\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3600\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3600\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3600\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3600\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 900\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 900\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 900\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 900\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       " Done!\n",
       "Grabbing style from haring_bw.jpg...\n",
       " 64\n",
       " 64\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 202500\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 64\n",
       " 64\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 202500\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 128\n",
       " 128\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 50625\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 128\n",
       " 128\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 50625\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 12769\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 12769\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 12769\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 256\n",
       " 256\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 12769\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3249\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3249\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3249\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 3249\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 841\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 841\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 841\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 512\n",
       " 512\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "\n",
       " 841\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " Done!\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Run Style2Vec\n",
    "\n",
    "style_vecs = {}\n",
    "-- grab our params (all relu layers except 6 and 7)\n",
    "local style_layers = params.style_layers:split(',')\n",
    "\n",
    "for label, image in pairs(style_images) do\n",
    "    io.write('Grabbing style from ' .. label .. '...')\n",
    "    params.label = label\n",
    "    local vec = Style2Vec(image, cnn, style_layers, params)\n",
    "    style_vecs[label] = vec\n",
    "    io.write(' Done!\\n')\n",
    "end\n",
    "\n",
    "-- the code above gives us style_vecs[\"haring_bw.jpg\"][\"relu2_1 \"] = torch.FloatTensor\n",
    "-- print(style_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- clean up a little\n",
    "cnn = nil\n",
    "style_images = nil\n",
    "collectgarbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distance at layer relu1_1 is: 1.000000\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu1_2 is: 1.000000\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu2_1 is: 0.984375\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu2_2 is: 1.000000\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu3_1 is: 0.996094\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu3_2 is: 1.000000\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu3_3 is: 1.000000\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu3_4 is: 0.996094\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu4_1 is: 0.968750\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu4_2 is: 0.953125\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu4_3 is: 0.984375\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu4_4 is: 0.972656\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu5_1 is: 0.984375\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu5_2 is: 0.958984\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu5_3 is: 0.925781\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Distance at layer relu5_4 is: 0.642368\t\n"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function CosineSimilarity(x, y)\n",
    "    local net = nn.Sequential()\n",
    "    net:add(nn.CosineDistance())\n",
    "    return net:forward({x, y})\n",
    "end\n",
    "\n",
    "function StyleDistance(x, y, sorted_layers)\n",
    "    -- this function will return the distance from each layer, assuming x and y\n",
    "    -- x[\"relu2_1 \"] = torch.FloatTensor\n",
    "    \n",
    "    for _, i in ipairs(sorted_layers) do -- can you tell I'm new to Lua?\n",
    "        local distance_vector = CosineSimilarity(x[i]:double(), y[i]:double())\n",
    "        local avg_distance = torch.mean(distance_vector)\n",
    "        \n",
    "        local msg ='Distance at layer %s is: %f'\n",
    "        print(string.format(msg, i, avg_distance))\n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "-- this is a little embarassing, no?\n",
    "local labels = params.style_layers:split(',')\n",
    "table.sort(labels)\n",
    "\n",
    "StyleDistance(style_vecs['haring_bw.jpg'], style_vecs['haring_bw.jpg'], labels)\n",
    "-- x = torch.Tensor({1, 2, 3})\n",
    "-- y = torch.Tensor({4, 5, 6})\n",
    "-- print(CosineSimilarity(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
